{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: scrapy.cfg already exists in /home/yannis/Projects/Ecole_IPSSI/2022-2023/WebScraping/Scrapy/WebScraping/MangaCrawler\r\n"
     ]
    }
   ],
   "source": [
    "# Création du dossier WebCrawler contenant l'ensemble des fichiers utiles au fonctionnement de scrapy\n",
    "!scrapy startproject MangaCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created spider 'mangascantrad' using template 'basic' in module:\n",
      "  MangaCrawler.spiders.mangascantrad\n"
     ]
    }
   ],
   "source": [
    "# création du projet Manga\n",
    "!cd MangaCrawler && scrapy genspider mangascantrad https://manga-scantrad.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter au fichier items.py & Liste des données qui seront récupérés par manga\n",
    "class MangacrawlerItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    title = scrapy.Field()\n",
    "    img = scrapy.Field()\n",
    "    rating = scrapy.Field()\n",
    "    last_chapter = scrapy.Field()\n",
    "    link = scrapy.Field()\n",
    "    genres = scrapy.Field()\n",
    "    published_date = scrapy.Field()\n",
    "    state = scrapy.Field()\n",
    "    nb_comments = scrapy.Field()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La class MangascantradSpider\n",
    "import scrapy\n",
    "from scrapy import Request\n",
    "from MangaCrawler.items import MangaGenres, MangacrawlerItem, DataBase\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy.orm import declarative_base, relationship\n",
    "\n",
    "class MangascantradSpider(scrapy.Spider):\n",
    "    name = 'mangascantrad'\n",
    "    allowed_domains = ['manga-scantrad.net']\n",
    "\n",
    "    # Liste des urls par pages\n",
    "    start_urls = [f'http://manga-scantrad.net/manga/page/{n}' for n in range(1, 31)]\n",
    "\n",
    "    # Création de la base de données\n",
    "    database = DataBase('database_manga')\n",
    "\n",
    "    # Creation des tables avec une relation ManyToMany\n",
    "    Base = declarative_base()\n",
    "    association_table = db.Table(\n",
    "        \"mangas_assoc_genres\",\n",
    "        Base.metadata,\n",
    "        db.Column(\"mangas_id\", db.ForeignKey(\"mangas.id_\")),\n",
    "        db.Column(\"mangas_genres_id\", db.ForeignKey(\"mangas_genres.id_\")),\n",
    "    )\n",
    "    database.create_table('mangas_genres',\n",
    "                          id_=db.Integer,\n",
    "                          name=db.String,\n",
    "                          )\n",
    "\n",
    "    database.create_table('mangas',\n",
    "                          id_=db.Integer,\n",
    "                          title=db.String,\n",
    "                          img=db.String,\n",
    "                          rating=db.String,\n",
    "                          last_chapter=db.String,\n",
    "                          link=db.String,\n",
    "                          genres=db.String,\n",
    "                          published_date=db.String,\n",
    "                          state=db.String,\n",
    "                          nb_comments=db.String,\n",
    "                          children=relationship(\"mangas_genres\", secondary=association_table)\n",
    "                          )\n",
    "\n",
    "    def start_requests(self):\n",
    "        print(\"iok\")\n",
    "        # for url in self.start_urls:\n",
    "        #     yield Request(url=url, callback=self.parse_manga)\n",
    "\n",
    "    def parse_manga(self, response):\n",
    "        mangas = response.css('div.js-categories-seasonal.js-block-list.list table tr')[1:]\n",
    "        for manga in mangas:\n",
    "            item = MangacrawlerItem()\n",
    "\n",
    "            # Nom manga\n",
    "            try:\n",
    "                item['name'] = manga.css('td')[1].css('a.hoverinfo_trigger.fw-b strong::text').get()\n",
    "            except:\n",
    "                item['name'] = 'None'\n",
    "\n",
    "            # Image manga\n",
    "            try:\n",
    "                item['img'] = manga.css('td')[0].css('a.hoverinfo_trigger img').attrib['data-src']\n",
    "            except:\n",
    "                item['img'] = 'None'\n",
    "\n",
    "            # Description manga\n",
    "            try:\n",
    "                item['description'] = manga.css('td')[1].css('div.pt4::text').get()\n",
    "            except:\n",
    "                item['description'] = 'None'\n",
    "\n",
    "            # Ajouter dans la base de données\n",
    "            self.database.add_row('manga',\n",
    "                                  name=item['name'],\n",
    "                                  img=item['img'],\n",
    "                                  description=item['description']\n",
    "                                  )\n",
    "            yield item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/sqlalchemy/sql/schema.py\", line 134, in _init_items\n",
      "    spwd = item._set_parent_with_dispatch\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\", line 1244, in __getattr__\n",
      "    return self._fallback_getattr(key)\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\", line 1218, in _fallback_getattr\n",
      "    raise AttributeError(key)\n",
      "AttributeError: _set_parent_with_dispatch\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yannis/.local/bin/scrapy\", line 8, in <module>\n",
      "    sys.exit(execute())\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/scrapy/cmdline.py\", line 153, in execute\n",
      "    cmd.crawler_process = CrawlerProcess(settings)\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/scrapy/crawler.py\", line 304, in __init__\n",
      "    super().__init__(settings)\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/scrapy/crawler.py\", line 181, in __init__\n",
      "    self.spider_loader = self._get_spider_loader(settings)\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/scrapy/crawler.py\", line 175, in _get_spider_loader\n",
      "    return loader_cls.from_settings(settings.frozencopy())\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/scrapy/spiderloader.py\", line 67, in from_settings\n",
      "    return cls(settings)\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/scrapy/spiderloader.py\", line 24, in __init__\n",
      "    self._load_all_spiders()\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/scrapy/spiderloader.py\", line 51, in _load_all_spiders\n",
      "    for module in walk_modules(name):\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/scrapy/utils/misc.py\", line 88, in walk_modules\n",
      "    submod = import_module(fullpath)\n",
      "  File \"/usr/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 790, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/yannis/Projects/Ecole_IPSSI/2022-2023/WebScraping/Scrapy/WebScraping/MangaCrawler/MangaCrawler/spiders/mangascantrad.py\", line 7, in <module>\n",
      "    class MangascantradSpider(scrapy.Spider):\n",
      "  File \"/home/yannis/Projects/Ecole_IPSSI/2022-2023/WebScraping/Scrapy/WebScraping/MangaCrawler/MangaCrawler/spiders/mangascantrad.py\", line 25, in MangascantradSpider\n",
      "    database.create_table('mangas_genres',\n",
      "  File \"/home/yannis/Projects/Ecole_IPSSI/2022-2023/WebScraping/Scrapy/WebScraping/MangaCrawler/MangaCrawler/items.py\", line 49, in create_table\n",
      "    colums = [db.Column(k, v, primary_key=True) if 'id_' in k else db.Column(k, v) for k, v in kwargs.items()]\n",
      "  File \"/home/yannis/Projects/Ecole_IPSSI/2022-2023/WebScraping/Scrapy/WebScraping/MangaCrawler/MangaCrawler/items.py\", line 49, in <listcomp>\n",
      "    colums = [db.Column(k, v, primary_key=True) if 'id_' in k else db.Column(k, v) for k, v in kwargs.items()]\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/sqlalchemy/sql/schema.py\", line 1765, in __init__\n",
      "    self._init_items(*args)\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/sqlalchemy/sql/schema.py\", line 136, in _init_items\n",
      "    util.raise_(\n",
      "  File \"/home/yannis/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py\", line 208, in raise_\n",
      "    raise exception\n",
      "sqlalchemy.exc.ArgumentError: 'SchemaItem' object, such as a 'Column' or a 'Constraint' expected, got <RelationshipProperty at 0x7f0c7f88c8c0; no key>\n"
     ]
    }
   ],
   "source": [
    "# Exécution de scrapy\n",
    "!cd MangaCrawler/MangaCrawler/spiders && scrapy crawl mangascantrad -o mangascantrad.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
